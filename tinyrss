#!/usr/bin/env python3
import concurrent.futures
import datetime
import functools
import html.parser
import os
import subprocess
import sys
import time
import textwrap
import wsgiref.handlers

import feedparser
import requests

def get(since, url):
    fmt = wsgiref.handlers.format_date_time
    r = requests.get(url, headers={'If-Modified-Since': fmt(since)})
    return r.text if r.status_code == 200 else ''

def pred(since, entry):
    dt = datetime.datetime
    keys = ['published_parsed', 'updated_parsed', 'created_parsed']
    key = min((i, k) for i, k in enumerate(keys) if k in entry)[1]
    return (dt(*entry[key][:6]) > dt.fromtimestamp(since))

def showfeed(url, content, pred):
    if not content:
        return
    feed = feedparser.parse(content)
    if feed.bozo:
        print('Failed to parse {}'.format(url), file=sys.stderr)
    for e in feed.entries:
        if pred(e):
            showentry(e)

def showentry(entry):
    curr = os.path.expanduser('~/.tinyrss/curr')
    with open(curr, 'w') as f:
        show = ShowContent(f)
        showfield(entry, 'title', f)
        showfield(entry, 'author', f)
        showfield(entry, 'link', f)
        for t in entry.get('content', []):
            show.feed(t.value)
            show.close()
    p = subprocess.Popen(['less', curr])
    p.wait()

def showfield(entry, k, f):
    if entry.has_key(k):
        print(entry.get(k), file=f)

class ShowContent(html.parser.HTMLParser):
    def __init__(self, f):
        super(ShowContent, self).__init__()
        self.f = f
        self.links = []
        self.par = []
        self.addlink = False

    def handle_starttag(self, tag, attrs):
        if tag == 'p':
            self.par = []
        elif tag == 'a':
            self.links.append(dict(attrs)['href'])
            self.addlink = True

    def handle_endtag(self, tag):
        if tag == 'p':
            print('\n'.join(textwrap.wrap(''.join(self.par), width=80)),
                  file=self.f, end='\n\n')
        elif tag == 'a':
            self.addlink = False

    def handle_data(self, data):
        self.par.append(data)
        if self.addlink:
            self.par.append('[{}]'.format(len(self.links)))


    def close(self):
        for i, l in enumerate(self.links):
            print('[{}] {}'.format(i + 1, l), file=self.f)
        super().close()

if __name__ == '__main__':
    with open(os.path.expanduser('~/.tinyrss/urls')) as f:
        urls = [x.strip() for x in f]
    with open(os.path.expanduser('~/.tinyrss/since')) as f:
        since = float(f.read())
    with open(os.path.expanduser('~/.tinyrss/since'), 'w') as f:
        print(time.time(), file=f)
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as e:
        responses = e.map(functools.partial(get, since), urls)
        p = functools.partial(pred, since)
        for u, r in zip(urls, responses):
            showfeed(u, r, p)
